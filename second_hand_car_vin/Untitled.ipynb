{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['35192037', 'https://m.che168.com/dealer/345873/35192037.html', '2019-11-02', '凯越 2008款 1.6LE-MT', '450000', '450900', '38', '875', '3817', 'LSGJA52UX8H149306', '2.00', '10', '12', '手动', '1.6L', '2008-09', '2次', '国V', '黑色', '玉林']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nurl = 'https://www.che168.com/dealer/341820/35240942.html?pvareaid=100519&userpid=440000&usercid=0#pos=43#page=2#rtype=10#isrecom=0#filter=38aa0_0a0_0a0_0#module=10#refreshid=0#recomid=0#queryid=1575458995$11$576f1ea4-36e7-4caa-b5b6-99b96759af2b$43299#cartype=10'\\nurl = 'https://www.che168.com/dealer/341820/35240942.html?usercid=0#pos=43#page=2#rtype=10#isrecom=0#filter=38aa0_0a0_0a0_0#module=10#refreshid=0#recomid=0#queryid=1575458995$11$576f1ea4-36e7-4caa-b5b6-99b96759af2b$43299#cartype=10'\\nr = session.get(url,headers=headers,timeout=30)\\nbsObj = BeautifulSoup(r.content, 'lxml')\\nprint(bsObj)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "import time\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/49.0.2623.112 Safari/537.36\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8\",\n",
    "    \"Connection\": \"close\",\n",
    "    \"Accept-Language\": \"zh-CN,zh;q=0.9\"}\n",
    "session = requests.Session()\n",
    "\n",
    "def get_CarInfo(url):\n",
    "    '''\n",
    "    获取每辆二手车HTML中的车辆信息\n",
    "    :param url: 手机端二手车URL\n",
    "    :return: 该二手车的重要信息\n",
    "    '''\n",
    "    # 车辆手机端与PC端链接URL（手机端主要获取VIN及其他重要信息，PC端获取外观颜色）\n",
    "    mobile_url = url\n",
    "    pc_url = url.replace('https://m.che168.com', 'https://www.che168.com')\n",
    "    # 一直访问单辆二手车信息网页，直到访问成功（最多10次）\n",
    "    get_time = 0\n",
    "    while get_time < 10:\n",
    "        try:\n",
    "            html = session.get(url, headers=headers, timeout=30)\n",
    "            time.sleep(3)\n",
    "            pc_html = session.get(pc_url, headers=headers,timeout=30)\n",
    "            html.close()\n",
    "            pc_html.close()\n",
    "        except:\n",
    "            get_time += 1\n",
    "            time.sleep(10)\n",
    "        else:\n",
    "            bsObj = BeautifulSoup(html.text, 'lxml')\n",
    "            pc_bsObj = BeautifulSoup(pc_html.content.decode('gb18030'), 'html.parser')\n",
    "            script = bsObj.find('body').find('script', {'type': 'text/javascript'}).get_text()\n",
    "            script = script.strip()\n",
    "            get_time = 10\n",
    "\n",
    "    # title\n",
    "    title = bsObj.find('h5', {'class': 'car-title two-line'}).get_text()\n",
    "    # infoid\n",
    "    infoid = re.search(re.compile(r\"infoId = parseInt\\('[\\d]*'\"), script).group()\n",
    "    infoid = re.search(re.compile(r\"'[\\d]*'\"), infoid).group()[1:-1]\n",
    "    # 二手信息公布时间\n",
    "    publicdate = re.search(re.compile(r\"publicdate: '[\\d-]*'\"), script).group()\n",
    "    publicdate = re.search(re.compile(r\"'[\\d-]*'\"), publicdate).group()[1:-1]\n",
    "    # 地区-省份/直辖市 and 城市 id\n",
    "    # location = bsObj.find('meta', {'name': 'location'})['content']\n",
    "    # location = re.search(re.compile(r\"province=\\S*;\"), location).group()\n",
    "    p_id = re.search(re.compile(r\"pid: '\\d*'\"), script).group()\n",
    "    p_id = re.search(re.compile(r\"'\\d*'\"), p_id).group()[1:-1]\n",
    "    c_id = re.search(re.compile(r\"cid: '\\d*'\"), script).group()\n",
    "    c_id = re.search(re.compile(r\"'\\d*'\"), c_id).group()[1:-1]\n",
    "    # 品牌id\n",
    "    brandid = re.search(re.compile(r\"brandid: '\\d*'\"), script).group()\n",
    "    brandid = re.search(re.compile(r\"'\\d*'\"), brandid).group()[1:-1]\n",
    "    # 车系id\n",
    "    seriesid = re.search(re.compile(r\"seriesid: '\\d*'\"), script).group()\n",
    "    seriesid = re.search(re.compile(r\"'\\d*'\"), seriesid).group()[1:-1]\n",
    "    # 车型id\n",
    "    specid = re.search(re.compile(r\"specid: '\\d*'\"), script).group()\n",
    "    specid = re.search(re.compile(r\"'\\d*'\"), specid).group()[1:-1]\n",
    "    # 二手价格\n",
    "    price = re.search(re.compile(r\"price: '[0-9\\.]*'\"), script).group()\n",
    "    price = re.search(re.compile(r\"'[0-9\\.]*'\"), price).group()[1:-1]\n",
    "    # 里程/万公里\n",
    "    mileage = re.search(re.compile(r\"mileage: '[0-9\\.]*'\"), script).group()\n",
    "    mileage = re.search(re.compile(r\"'[0-9\\.]*'\"), mileage).group()[1:-1]\n",
    "    # 车龄\n",
    "    carAge = re.search(re.compile(r\"carAge: '[0-9\\.]*'\"), script).group()\n",
    "    carAge = re.search(re.compile(r\"'[0-9\\.]*'\"), carAge).group()[1:-1]\n",
    "    # 车辆档案\n",
    "    base_data = bsObj.find('ul', {'class': 'base-data'}).find_all('li')\n",
    "    # 车辆档案-首次上牌\n",
    "    registedate = base_data[0].find('p', {'class': 'item-status'}).get_text()\n",
    "    # 车辆档案-查询准迁地-国几\n",
    "    how_much_guo = base_data[2].find('p', {'class': 'item-status'}).get_text()\n",
    "    # 车辆档案-排量、变速箱\n",
    "    power = base_data[3].find('p', {'class': 'item-status'}).get_text()\n",
    "    trans = base_data[4].find('p', {'class': 'item-status'}).get_text()\n",
    "    # 过户次数\n",
    "    guo_hu = base_data[5].find('p', {'class': 'item-status'}).get_text()\n",
    "    # 车辆档案-牌照地\n",
    "    license_plate_area = base_data[6].find('p', {'class': 'item-status'}).get_text()\n",
    "    vincode = re.search(re.compile(r\"vincode: '\\w*'\"), script).group()\n",
    "    vincode = re.search(re.compile(r\"'\\w*'\"), vincode).group()[1:-1]\n",
    "    # 车身颜色\n",
    "    if (\"/dealer/\" in url) or (\"/personal/\" in url):\n",
    "        color = pc_bsObj.find(text='车身颜色').parent.parent.get_text()\n",
    "        color = color.replace('车身颜色', '')\n",
    "    elif \"/lianmeng/\" in url:\n",
    "        color = pc_bsObj.find(text='颜　　色：').parent.parent.get_text()\n",
    "        color = color.replace('颜　　色：', '').strip()\n",
    "\n",
    "    CarInfo_list = [infoid, mobile_url, publicdate, title, p_id, c_id, brandid, seriesid, specid, vincode,\n",
    "                    price, mileage, carAge, trans, power, registedate, guo_hu, how_much_guo, color,\n",
    "                    license_plate_area, html.text]\n",
    "\n",
    "        #print(url, '未正确获取二手车信息！')\n",
    "        #CarInfo_list = [\"-\", mobile_url, \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\", \"-\",\n",
    "         #               \"-\", \"-\", \"-\", \"-\", html.text]\n",
    "    return CarInfo_list\n",
    "\n",
    "def get_page_car_url(address, brand, page):\n",
    "    url = 'https://www.che168.com/%s/%s/a0_0msdgscncgpi1ltocsp%dex/' % (address, brand, page)\n",
    "    car_url_list = []\n",
    "    html = urlopen(url, timeout=30)\n",
    "    bsObj = BeautifulSoup(html, 'lxml')\n",
    "    li = bsObj.find_all('li', {'class': 'cards-li list-photo-li'})\n",
    "    for i in li:\n",
    "        a_tag = i.find('a')\n",
    "        a_tag_href = a_tag['href']\n",
    "        car_url_list.append(a_tag_href)\n",
    "    return car_url_list\n",
    "def get_page_car_url_new(address, brand, page):\n",
    "    url = 'https://www.che168.com/%s/%s/a0_0msdgscncgpi1ltocsp%dex/' % (address, brand, page)\n",
    "    car_url_list = []\n",
    "    html = session.get(url, headers=headers, timeout=30)\n",
    "    bsObj = BeautifulSoup(html.content, 'lxml')\n",
    "    li = bsObj.find_all('li', {'class': 'cards-li list-photo-li'})\n",
    "    for i in li:\n",
    "        a_tag = i.find('a')\n",
    "        a_tag_href = a_tag['href']\n",
    "        car_url_list.append(a_tag_href)\n",
    "    return car_url_list\n",
    "\n",
    "\n",
    "url = 'https://m.che168.com/dealer/345873/35192037.html'\n",
    "lists = get_CarInfo(url)\n",
    "print(lists[:-1])\n",
    "'''\n",
    "url = 'https://www.che168.com/dealer/341820/35240942.html?pvareaid=100519&userpid=440000&usercid=0#pos=43#page=2#rtype=10#isrecom=0#filter=38aa0_0a0_0a0_0#module=10#refreshid=0#recomid=0#queryid=1575458995$11$576f1ea4-36e7-4caa-b5b6-99b96759af2b$43299#cartype=10'\n",
    "url = 'https://www.che168.com/dealer/341820/35240942.html?usercid=0#pos=43#page=2#rtype=10#isrecom=0#filter=38aa0_0a0_0a0_0#module=10#refreshid=0#recomid=0#queryid=1575458995$11$576f1ea4-36e7-4caa-b5b6-99b96759af2b$43299#cartype=10'\n",
    "r = session.get(url,headers=headers,timeout=30)\n",
    "bsObj = BeautifulSoup(r.content, 'lxml')\n",
    "print(bsObj)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "'''原有数据添加info_ID'''\n",
    "import pymysql\n",
    "\n",
    "def add_info_id():\n",
    "    conn = pymysql.connect(host='127.0.0.1', user='root', passwd='123456', db='second_hand_car_info', charset='utf8')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"USE second_hand_car_info\")\n",
    "    sql = '''\n",
    "        SELECT mobile_url FROM `second_hand_car`CONVERT('123',SIGNED);\n",
    "    '''\n",
    "    sql = '''\n",
    "        SELECT CONVERT(REPLACE(SUBSTRING_INDEX(mobile_url,'/',-1),'.html',''),SIGNED)  FROM `second_hand_car` LIMIT 5\n",
    "    '''\n",
    "    cur.execute(sql)\n",
    "    result = cur.fetchall()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    return result\n",
    "\n",
    "def update_registedate():\n",
    "    conn = pymysql.connect(host='127.0.0.1', user='root', passwd='123456', db='second_hand_car_info', charset='utf8')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"USE second_hand_car_info\")\n",
    "    \n",
    "    sql = '''\n",
    "        UPDATE `second_hand_car`\n",
    "        SET registedate = REPLACE(REPLACE(registedate,'年','-'),'月','')\n",
    "    '''\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    \n",
    "def update_trans_and_power():\n",
    "    conn = pymysql.connect(host='127.0.0.1', user='root', passwd='123456', db='second_hand_car_info', charset='utf8')\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"USE second_hand_car_info\")\n",
    "    sql = '''\n",
    "        SELECT TransAndPower,SUBSTRING_INDEX(TransAndPower,'/',1),SUBSTRING_INDEX(TransAndPower,'/',-1)\n",
    "        FROM second_hand_car\n",
    "        LIMIT 100\n",
    "    '''\n",
    "    sql = '''\n",
    "        UPDATE `second_hand_car`\n",
    "        SET trans = SUBSTRING_INDEX(TransAndPower,'/',1),\n",
    "            power = SUBSTRING_INDEX(TransAndPower,'/',-1)\n",
    "        WHERE TransAndPower NOT IN ('-')\n",
    "    '''\n",
    "    cur.execute(sql)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "    \n",
    "\n",
    "update_trans_and_power()\n",
    "print('GAME OVER！')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://m.che168.com/personal/del_33428056.html'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "\n",
    "# bsObj = BeautifulSoup(r.content.decode('gb18030'),'html.parser')\n",
    "# bsObj = BeautifulSoup(r.content,'lxml')\n",
    "bsObj = BeautifulSoup(r.text, 'lxml')\n",
    "a = bsObj.find('div', {'class': 'wrong'}).get_text()\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1,3,4]\n",
    "b = None\n",
    "a.append(b)\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
